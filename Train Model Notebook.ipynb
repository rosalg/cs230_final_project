{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define variables\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize pixel function\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def _normalize_img(img, label):\n",
    "    image = tf.cast(img/255. ,tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update Data Directory Name\n",
    "\n",
    "data_dir = 'data_folder/all_data_processed' #Change this to lfw & pubfig dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20804 files belonging to 1751 classes.\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset\n",
    "\n",
    "lfw_pubfig_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  shuffle=True,\n",
    "  seed=42,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "lfw_pubfig_ds_norm = lfw_pubfig_ds.map(_normalize_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Dataset Split 0.7/0.15/0.15\n",
    "\n",
    "train_split = 0.7\n",
    "val_split = 0.15\n",
    "test_split = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Dataset\n",
    "\n",
    "ds_size = len(list(lfw_pubfig_ds_norm))\n",
    "train_size = int(train_split * ds_size)\n",
    "val_size = int(val_split * ds_size)\n",
    "test_size = int(test_split * ds_size)\n",
    "\n",
    "train_ds = lfw_pubfig_ds_norm.take(train_size)    \n",
    "val_ds = lfw_pubfig_ds_norm.skip(train_size).take(val_size)\n",
    "test_ds = lfw_pubfig_ds_norm.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14560 (TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
      "3104 (TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
      "3104 (TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "#Print Dataset Sizes\n",
    "\n",
    "print(len(list(train_ds)) * batch_size, train_ds.element_spec) # Default Batches of 32\n",
    "print(len(list(val_ds)) * batch_size, val_ds.element_spec) # Default Batches of 32\n",
    "print(len(list(test_ds)) * batch_size, test_ds.element_spec) # Default Batches of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Baseline Model Class\n",
    "\n",
    "class BaselineModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        \n",
    "        self.input_layer = tf.keras.layers.Input((img_height, img_width, img_channels))\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=7, padding='same', activation='relu')\n",
    "        self.mpool1 = tf.keras.layers.MaxPooling2D(pool_size=2)\n",
    "        \n",
    "        self.flat1 = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(128, activation=None)\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.mpool1(x)\n",
    "        x = self.flat1(x)\n",
    "        x = self.fc1(x)\n",
    "        out = self.output_layer(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def model(self):\n",
    "        return tf.keras.Model(inputs=self.input_layer, outputs=self.call(self.input_layer))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Advanced Model Class (Insert Model Architecture)\n",
    "\n",
    "class AdvancedModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(AdvancedModel, self).__init__()\n",
    "        \n",
    "        self.input_layer = tf.keras.layers.Input((img_height, img_width, img_channels))\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=7, padding='same', activation='relu')\n",
    "        self.mpool1 = tf.keras.layers.MaxPooling2D(pool_size=2)\n",
    "        \n",
    "        self.flat1 = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(128, activation=None)\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.mpool1(x)\n",
    "        x = self.flat1(x)\n",
    "        x = self.fc1(x)\n",
    "        out = self.output_layer(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def model(self):\n",
    "        return tf.keras.Model(inputs=self.input_layer, outputs=self.call(self.input_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Model\n",
    "\n",
    "#Uncomment for Baseline Model\n",
    "model_name = 'baseline'\n",
    "model = BaselineModel()\n",
    "\n",
    "#Uncomment for Advanced Model\n",
    "#model_name = 'advanced'\n",
    "#model = AdvancedModel()\n",
    "\n",
    "model.model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compliel Model with Adam Optimizer and Triplet Loss\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tfa.losses.TripletHardLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "EPOCHS = 50\n",
    "\n",
    "history = model.fit(\n",
    "        x=train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model\n",
    "model.save('saved_model/' + model_name + '_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save training data\n",
    "import pandas as pd\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:   \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'saved_model/' + model_name + '_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constuct a database of known image encodings from the training/verification dataset as a reference to evaluate the test dataset\n",
    "\n",
    "pubfig_db_dict = {}\n",
    "for images, labels in train_ds.take(len(list(train_ds))):\n",
    "    for i in range(labels.shape[0]):\n",
    "        if int(labels[i]) not in pubfig_db_dict:\n",
    "            pubfig_db_dict[int(labels[i])] = model.predict(np.expand_dims(images[i], axis=0))\n",
    "            \n",
    "for images, labels in val_ds.take(len(list(val_ds))):\n",
    "    for i in range(labels.shape[0]):\n",
    "        if int(labels[i]) not in pubfig_db_dict:\n",
    "            pubfig_db_dict[int(labels[i])] = model.predict(np.expand_dims(images[i], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Each Image in the test set, compute the closest image embedding\n",
    "#If it is closer than the threshold, classify the image as that class\n",
    "#If it is further than the threshold, the test image is not in the referance classes\n",
    "\n",
    "test_num = 0\n",
    "test_correct = 0\n",
    "total_distance = 0\n",
    "\n",
    "threshold = 1.3\n",
    "\n",
    "test_samples = len(list(test_ds))\n",
    "\n",
    "for images, labels in test_ds.take(test_samples):\n",
    "    for i in range(labels.shape[0]):\n",
    "        #Establish Target and test encoding\n",
    "        test_label = int(labels[i])\n",
    "        test_encoding = model.predict(np.expand_dims(images[i], axis=0))\n",
    "        \n",
    "        # Initialize \"min_dist\" to a large value, say 100 (â‰ˆ1 line)\n",
    "        min_dist = 100\n",
    "        min_label = 0\n",
    "        \n",
    "        #Loop through all images in dataset and find closests\n",
    "        for key in pubfig_db_dict.keys():\n",
    "            db_enc = pubfig_db_dict[key]\n",
    "            \n",
    "            #compute L2 distance\n",
    "            dist = np.linalg.norm(db_enc - test_encoding)\n",
    "            \n",
    "            #set new label if smallest distance seen\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_label = key\n",
    "                \n",
    "            if key == test_label:\n",
    "                total_distance += dist\n",
    "        \n",
    "        test_num += 1\n",
    "        if min_dist < threshold:\n",
    "            if min_label == test_label:\n",
    "                test_correct += 1\n",
    "        elif test_label not in pubfig_db_dict:\n",
    "            test_correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Facial Recognition Accuracy and Average Distance from correct class\n",
    "\n",
    "print(test_correct/test_num)\n",
    "print(total_distance/test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
